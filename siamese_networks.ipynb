{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/gupta24789/siamese-networks/blob/main/siamese_networks.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-ynB5xi1Aw0X"
      },
      "outputs": [],
      "source": [
        "# !wget https://github.com/gupta24789/siamese-networks/raw/main/data.zip\n",
        "# !unzip data.zip"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "x9UWtI5VAw0Z"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "os.environ['CUDA_VISIBLE_DEVICES'] = \"1\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "K94wpPLlAw0a"
      },
      "outputs": [],
      "source": [
        "import random\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import itertools\n",
        "from nltk import tokenize\n",
        "from tqdm import tqdm, tqdm_notebook\n",
        "from sklearn.metrics import classification_report, confusion_matrix\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "from torch.nn.utils.rnn import pad_sequence, pack_padded_sequence\n",
        "from torch.utils.data import DataLoader, Dataset\n",
        "\n",
        "\n",
        "import pytorch_lightning as pl"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bM_EQ_iTAw0b"
      },
      "source": [
        "## Set Seed"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3Kdd_4viAw0d",
        "outputId": "cce869d4-1bf7-4d07-e257-bdd523b19fb3"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Seed set to 34\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "34"
            ]
          },
          "execution_count": 4,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "seed = 34\n",
        "random.seed(seed)\n",
        "torch.manual_seed(seed)\n",
        "pl.seed_everything(seed)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ULhXxOTPAw0e"
      },
      "source": [
        "## Read Data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qt6IqWeMAw0f",
        "outputId": "785e4ec9-8a52-420e-c297-52d171f07a17"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "train shape : (283045, 6)\n",
            "test shape : (121305, 6)\n"
          ]
        }
      ],
      "source": [
        "train_df = pd.read_csv(\"data/train.csv\")\n",
        "test_df = pd.read_csv(\"data/test.csv\")\n",
        "test_df = test_df.dropna().reset_index(drop = True)\n",
        "\n",
        "print(f'train shape : {train_df.shape}')\n",
        "print(f'test shape : {test_df.shape}')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rIfyeoFgAw0f",
        "outputId": "5323e175-1630-4966-87ab-48cb48ef1dd7"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>qid1</th>\n",
              "      <th>qid2</th>\n",
              "      <th>question1</th>\n",
              "      <th>question2</th>\n",
              "      <th>is_duplicate</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>27186</td>\n",
              "      <td>54210</td>\n",
              "      <td>54211</td>\n",
              "      <td>What will happen if Google starts charging for...</td>\n",
              "      <td>Is it normal to Google search every question y...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>246439</td>\n",
              "      <td>485308</td>\n",
              "      <td>485309</td>\n",
              "      <td>Why are bats associated with vampires?</td>\n",
              "      <td>Do vampires get periods?</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>298392</td>\n",
              "      <td>586093</td>\n",
              "      <td>586094</td>\n",
              "      <td>How can I start learning data science?</td>\n",
              "      <td>How can I start learning data science and beco...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "       id    qid1    qid2                                          question1  \\\n",
              "0   27186   54210   54211  What will happen if Google starts charging for...   \n",
              "1  246439  485308  485309             Why are bats associated with vampires?   \n",
              "2  298392  586093  586094             How can I start learning data science?   \n",
              "\n",
              "                                           question2  is_duplicate  \n",
              "0  Is it normal to Google search every question y...             0  \n",
              "1                           Do vampires get periods?             0  \n",
              "2  How can I start learning data science and beco...             1  "
            ]
          },
          "execution_count": 6,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "train_df.head(3)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gxvwUpSPAw0g",
        "outputId": "47a1fa28-a472-46e1-c484-1527fe6222d4"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>qid1</th>\n",
              "      <th>qid2</th>\n",
              "      <th>question1</th>\n",
              "      <th>question2</th>\n",
              "      <th>is_duplicate</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>291513</td>\n",
              "      <td>572739</td>\n",
              "      <td>572740</td>\n",
              "      <td>What Rolling Stone song has the lyrics “oh and...</td>\n",
              "      <td>What's the point in living if you're so depres...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>58652</td>\n",
              "      <td>116675</td>\n",
              "      <td>76915</td>\n",
              "      <td>Do you have a Business-Plan to help the poor p...</td>\n",
              "      <td>Suppose you run a mobile business which genera...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>118294</td>\n",
              "      <td>139357</td>\n",
              "      <td>234460</td>\n",
              "      <td>Where's a good university to study Computer Sc...</td>\n",
              "      <td>What are some good UK universities in computer...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "       id    qid1    qid2                                          question1  \\\n",
              "0  291513  572739  572740  What Rolling Stone song has the lyrics “oh and...   \n",
              "1   58652  116675   76915  Do you have a Business-Plan to help the poor p...   \n",
              "2  118294  139357  234460  Where's a good university to study Computer Sc...   \n",
              "\n",
              "                                           question2  is_duplicate  \n",
              "0  What's the point in living if you're so depres...             0  \n",
              "1  Suppose you run a mobile business which genera...             0  \n",
              "2  What are some good UK universities in computer...             1  "
            ]
          },
          "execution_count": 7,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "test_df.head(3)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KjFo29jsAw0h"
      },
      "source": [
        "## Prepare Data\n",
        "\n",
        "\n",
        "The data is setup so that $v_{1\\_1}$ and $v_{2\\_1}$ represent duplicate inputs, but they are not duplicates with any other rows in the batch. This means $v_{1\\_1}$ and $v_{2\\_1}$ (green and green) have more similar vectors than say $v_{1\\_1}$ and $v_{2\\_2}$ (green and magenta).\n",
        "\n",
        "<img src = 'images/v1v2_stacked.png' width=\"width\" height=\"height\" style=\"height:250px;\"/>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZJMOTFYDAw0h"
      },
      "outputs": [],
      "source": [
        "## Create vocab using duplicates questions only\n",
        "Q1_train_sents = train_df.loc[train_df.is_duplicate==1,'question1'].tolist()\n",
        "Q2_train_sents = train_df.loc[train_df.is_duplicate==1,'question2'].tolist()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4BQWGxP3Aw0i",
        "outputId": "634d4bd6-7a62-4bc6-b8b8-3104702b8e4c"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "['How can I start learning data science?',\n",
              " 'Which is the best book to understand tensors?',\n",
              " 'Who viewed my profile on Instagram?']"
            ]
          },
          "execution_count": 9,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "Q1_train_sents[:3]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HUxP2UYFAw0j",
        "outputId": "9651e0b0-32f9-4b18-cc4e-58634a4909ac"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "['How can I start learning data science and become master in it?',\n",
              " 'Which is the best book to study TENSOR for general relativity from basic?',\n",
              " 'Can people see if you have viewed their instagram?']"
            ]
          },
          "execution_count": 10,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "Q2_train_sents[:3]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Xivk7p7-Aw0j",
        "outputId": "83e043e2-e960-43a2-d2ee-52d8c6d2a297"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Vocab 35289\n",
            "PAD ID : 0\n",
            "UNK ID : 1\n"
          ]
        }
      ],
      "source": [
        "## merge q1 & q2\n",
        "train_sents = Q1_train_sents + Q2_train_sents\n",
        "tokens = [tokenize.word_tokenize(sent) for sent in train_sents]\n",
        "tokens = list(set(itertools.chain.from_iterable(tokens)))\n",
        "\n",
        "special_tokens = ['__PAD__', '__UNK__']\n",
        "tokens = special_tokens + tokens\n",
        "\n",
        "vocab = {w:i for i,w in enumerate(tokens)}\n",
        "idx2word = {i:w for w,i in vocab.items()}\n",
        "\n",
        "UNK_ID = vocab['__UNK__']\n",
        "PAD_ID = vocab['__PAD__']\n",
        "\n",
        "print(f\"Vocab {len(vocab)}\")\n",
        "print(f\"PAD ID : {PAD_ID}\")\n",
        "print(f\"UNK ID : {UNK_ID}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fLXVIVAIAw0k"
      },
      "outputs": [],
      "source": [
        "def encode_sent_to_number(sent):\n",
        "    sent_list = tokenize.word_tokenize(sent)\n",
        "    encoded_sent = []\n",
        "\n",
        "    for w in sent_list:\n",
        "        encoded_sent.append(vocab.get(w, UNK_ID))\n",
        "\n",
        "    return encoded_sent"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AAHT9uY5Aw0l"
      },
      "outputs": [],
      "source": [
        "Q1_train_encoded = [encode_sent_to_number(sent) for sent in Q1_train_sents]\n",
        "Q2_train_encoded = [encode_sent_to_number(sent) for sent in Q2_train_sents]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9ptg7UMQAw0l"
      },
      "outputs": [],
      "source": [
        "Q1_test_encoded = [encode_sent_to_number(sent) for sent in test_df.question1.tolist()]\n",
        "Q2_test_encoded = [encode_sent_to_number(sent) for sent in test_df.question2.tolist()]\n",
        "y_test = test_df.is_duplicate.tolist()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "t_3sSvl8Aw0m"
      },
      "source": [
        "## Data Loader"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ogMUTY15Aw0m"
      },
      "outputs": [],
      "source": [
        "def custom_collate(batch):\n",
        "\n",
        "    q1 = [torch.tensor(item[0]) for item in batch]\n",
        "    q1_lengths = torch.tensor([len(item[0]) for item in batch] )\n",
        "\n",
        "\n",
        "    q2 = [torch.tensor(item[1]) for item in batch]\n",
        "    q2_lengths = torch.tensor([len(item[1]) for item in batch])\n",
        "\n",
        "    padded_q1 = pad_sequence(q1, batch_first= True, padding_value= PAD_ID)\n",
        "    padded_q2 = pad_sequence(q2, batch_first= True, padding_value= PAD_ID)\n",
        "\n",
        "    batch = {\"q1\": padded_q1, \"q2\": padded_q2,\"q1_lengths\": q1_lengths, \"q2_lengths\": q2_lengths}\n",
        "    return batch"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7LDE0Tz3Aw0m",
        "outputId": "5723fd62-9948-451b-f964-f2e87edadfc7"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(torch.Size([3, 9]), torch.Size([3, 14]), torch.Size([3]), torch.Size([3]))"
            ]
          },
          "execution_count": 16,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "batch_size = 3\n",
        "train_dl = DataLoader(list(zip(Q1_train_encoded,Q2_train_encoded)), batch_size = batch_size, shuffle=False, collate_fn= custom_collate)\n",
        "example = next(iter(train_dl))\n",
        "example['q1'].shape, example['q2'].shape, example['q1_lengths'].shape, example['q2_lengths'].shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tv01uIu_Aw0n",
        "outputId": "33001a9e-88e1-4b43-e547-02a2e032e22b"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "tensor([[14883, 14283,  5318,   852,   850, 19756, 27515, 25929,     0],\n",
              "        [ 1071, 14812, 13212, 23460, 15598, 13934, 31872,  3933, 25929],\n",
              "        [13617, 25576,   959,  9670, 12207,  3173, 25929,     0,     0]])"
            ]
          },
          "execution_count": 17,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "example['q1']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4wqFO3mAAw0n",
        "outputId": "53bde3c6-9649-42d8-c590-04d6f81edfb5"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "tensor([8, 9, 7])"
            ]
          },
          "execution_count": 18,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "example['q1_lengths']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "U4OVUEdsAw0n"
      },
      "outputs": [],
      "source": [
        "## dataloaders\n",
        "batch_size = 256\n",
        "train_dl = DataLoader(list(zip(Q1_train_encoded,Q2_train_encoded)), batch_size = batch_size, shuffle=True, collate_fn= custom_collate)\n",
        "val_dl = DataLoader(list(zip(Q1_test_encoded,Q2_test_encoded)), batch_size = batch_size, shuffle=False, collate_fn= custom_collate)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cObtzHp9Aw0o"
      },
      "source": [
        "### Pretained Embeddding"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GfqAaUQ2Aw0o",
        "outputId": "70bb8683-1d83-43a9-9d8a-73014d1a2561"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/tmp/ipykernel_28305/1626787543.py:29: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:230.)\n",
            "  return torch.tensor(df_list)\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "torch.Size([35289, 100])"
            ]
          },
          "execution_count": 20,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "def load_pretrain_emb(filepath):\n",
        "    lines = open(filepath,\"r\").readlines()\n",
        "    embedd_dict = {}\n",
        "    for line in lines:\n",
        "        if len(line)>0:\n",
        "            tokens = line.strip().split(\" \")\n",
        "            word = tokens[0]\n",
        "            vec = tokens[1:]\n",
        "            vec = np.array(vec).astype(float)\n",
        "            embedd_dict[word]= vec\n",
        "\n",
        "    return embedd_dict\n",
        "\n",
        "def build_pretrain_embedding(filepath, vocab, emb_dim):\n",
        "    embedd_dict = load_pretrain_emb(filepath)\n",
        "\n",
        "    df_list = []\n",
        "\n",
        "    for w,i in vocab.items():\n",
        "        if w in embedd_dict:\n",
        "            df_list.append(torch.tensor(embedd_dict[w]))\n",
        "        elif w.lower() in embedd_dict:\n",
        "            df_list.append(embedd_dict[w.lower()])\n",
        "        else:\n",
        "            random_vec = np.random.normal(size = (emb_dim))\n",
        "            df_list.append(random_vec)\n",
        "\n",
        "\n",
        "    return torch.tensor(df_list)\n",
        "\n",
        "\n",
        "\n",
        "weights = build_pretrain_embedding(\"embeddings/glove.6B.100d.txt\", vocab, emb_dim=100)\n",
        "weights.shape"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qsnhid5-Aw0o"
      },
      "source": [
        "## Model\n",
        "\n",
        "You will now implement the `TripletLoss`.<br>\n",
        "As explained in the lecture, loss is composed of two terms. One term utilizes the mean of all the non duplicates, the second utilizes the *closest negative*. Our loss expression is then:\n",
        "\n",
        "\\begin{align}\n",
        " \\mathcal{Loss_1(A,P,N)} &=\\max \\left( -cos(A,P)  + mean_{neg} +\\alpha, 0\\right) \\\\\n",
        " \\mathcal{Loss_2(A,P,N)} &=\\max \\left( -cos(A,P)  + closest_{neg} +\\alpha, 0\\right) \\\\\n",
        "\\mathcal{Loss(A,P,N)} &= mean(Loss_1 + Loss_2) \\\\\n",
        "\\end{align}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "J9NveIIoAw0o"
      },
      "outputs": [],
      "source": [
        "class SiameseModel(pl.LightningModule):\n",
        "\n",
        "    def __init__(self, vocab_size, emb_dim, hidden_dim, margin, threshold, learning_rate, bidirectional, dropout, num_layers, use_pretrained):\n",
        "        super().__init__()\n",
        "        self.bidirectional = bidirectional\n",
        "        self.use_pretrained = use_pretrained\n",
        "        self.learning_rate = learning_rate\n",
        "        self.margin = margin\n",
        "        self.threhold = threshold\n",
        "        self.val_loss = []\n",
        "\n",
        "        # layers\n",
        "        self.embedding = nn.Embedding(vocab_size, emb_dim, padding_idx=PAD_ID)\n",
        "        if use_pretrained:\n",
        "            self.embedding.weight.data.copy_(weights)\n",
        "        else:\n",
        "            self.embedding.weight.data.copy_(torch.from_numpy(self.random_embedding(vocab_size, emb_dim)))\n",
        "\n",
        "        self.lstm = nn.LSTM(emb_dim, hidden_dim, batch_first = True, num_layers = num_layers, bidirectional = bidirectional, dropout = dropout)\n",
        "        self.linear = nn.Linear(hidden_dim * 2 if bidirectional else hidden_dim, hidden_dim)\n",
        "        self.relu = nn.ReLU()\n",
        "\n",
        "    def random_embedding(self, vocab_size, embedding_dim):\n",
        "        pretrain_emb = np.empty([vocab_size, embedding_dim])\n",
        "        scale = np.sqrt(3.0 / embedding_dim)\n",
        "        for index in range(1, vocab_size):\n",
        "            pretrain_emb[index, :] = np.random.uniform(-scale, scale, [1, embedding_dim])\n",
        "        return pretrain_emb\n",
        "\n",
        "    def loss_fn(self, scores):\n",
        "\n",
        "        device = \"cuda\" if scores.is_cuda else \"cpu\"\n",
        "        batch_size = len(scores)\n",
        "        positive = torch.diagonal(scores)\n",
        "        negative_zero_on_duplicate = scores * (1.0 - torch.eye(batch_size)).to(device)\n",
        "        mean_negative = torch.sum(negative_zero_on_duplicate, axis=1) / (batch_size-1)\n",
        "\n",
        "        negative_without_positive = scores - 2.0 * torch.eye(batch_size).to(device)\n",
        "        closest_negative, _ = negative_without_positive.max(axis=1)\n",
        "\n",
        "        # print(f\"scores : \\n{scores}\")\n",
        "        # print(\"positive : \", positive)\n",
        "        # print(f\"neg : {negative_zero_on_duplicate}\")\n",
        "        # print(\"mean_negative : \", mean_negative)\n",
        "        # print(\"closest_negative : \", closest_negative)\n",
        "\n",
        "        triplet_loss1 = torch.maximum(torch.tensor(0.0), self.margin - positive + closest_negative)\n",
        "        triplet_loss2 = torch.maximum(torch.tensor(0.0), self.margin - positive + mean_negative)\n",
        "        triplet_loss = torch.mean(triplet_loss1 + triplet_loss2)\n",
        "        return triplet_loss\n",
        "\n",
        "    def get_normalize_vector(self, q, q_lengths):\n",
        "        out = self.embedding(q)\n",
        "        ## out : [batch size, sent len, emb dim]\n",
        "        packed_input = pack_padded_sequence(out, lengths= q_lengths.to('cpu'), batch_first = True, enforce_sorted=False)\n",
        "        packed_output, (hidden, cell) = self.lstm(packed_input)\n",
        "        out, output_lengths = nn.utils.rnn.pad_packed_sequence(packed_output, batch_first = True)\n",
        "        ## out : [batch size, sent len, hidden dim * bidirectional]\n",
        "        # hidden : [num_layers * bidirectional, batch size,hidden dim]\n",
        "\n",
        "        if self.bidirectional:\n",
        "            out = torch.cat((hidden[-2,:,:], hidden[-1,:,:]), dim = 1)\n",
        "        else:\n",
        "            out = hidden[-1,:,:]\n",
        "\n",
        "        ## out : [batch size, hidden_dim * bidirectional]\n",
        "        # out = torch.mean(out, dim = 1)\n",
        "        ## [batch size, hidden dim * bidirectional]\n",
        "        # out = self.relu(self.linear(out))\n",
        "        # print(out.shape)\n",
        "        out = F.normalize(out, p = 2)\n",
        "\n",
        "        return out\n",
        "\n",
        "    def forward(self, q1, q2, q1_lengths, q2_lengths):\n",
        "        q1_vec = self.get_normalize_vector(q1, q1_lengths)\n",
        "        # print(q1_vec.shape)\n",
        "        q2_vec = self.get_normalize_vector(q2, q2_lengths)\n",
        "        # print(q2_vec.shape)\n",
        "        return (q1_vec, q2_vec)\n",
        "\n",
        "    def training_step(self, batch):\n",
        "        q1,q2,q1_lengths, q2_lengths = batch['q1'], batch['q2'],batch['q1_lengths'], batch['q2_lengths']\n",
        "        q1_vec,q2_vec = self(q1,q2,q1_lengths, q2_lengths)\n",
        "        scores = torch.matmul(q1_vec, q2_vec.T)\n",
        "        loss = self.loss_fn(scores)\n",
        "        self.log_dict({\"train_loss\": loss}, on_step = False, on_epoch = True, prog_bar=True)\n",
        "        return loss\n",
        "\n",
        "    def validation_step(self, batch):\n",
        "        q1,q2,q1_lengths, q2_lengths = batch['q1'], batch['q2'],batch['q1_lengths'], batch['q2_lengths']\n",
        "        q1_vec,q2_vec = self(q1,q2,q1_lengths, q2_lengths)\n",
        "        scores = torch.matmul(q1_vec, q2_vec.T)\n",
        "        loss = self.loss_fn(scores)\n",
        "        self.val_loss.append(loss.item())\n",
        "        self.log_dict({\"val_loss\": loss}, on_step = False, on_epoch = True, prog_bar=True)\n",
        "        return loss\n",
        "\n",
        "    def on_validation_epoch_end(self):\n",
        "        print(f\"Current Epoch : {self.current_epoch} Valiadtion Loss : {np.mean(self.val_loss)}\")\n",
        "        self.val_loss = []\n",
        "\n",
        "    def configure_optimizers(self):\n",
        "        optimizer = optim.Adam(self.parameters(), lr = self.learning_rate)\n",
        "        return optimizer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QsxLQlV1Aw0p",
        "outputId": "cf0b32e7-4b11-4180-bb5e-c483fe9be532"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "SiameseModel(\n",
            "  (embedding): Embedding(35289, 100, padding_idx=0)\n",
            "  (lstm): LSTM(100, 150, batch_first=True, dropout=0.25)\n",
            "  (linear): Linear(in_features=150, out_features=150, bias=True)\n",
            "  (relu): ReLU()\n",
            ")\n",
            "tensor(0.4927, grad_fn=<MeanBackward0>)\n",
            "tensor([[0.9736, 0.9567, 0.9573],\n",
            "        [0.9556, 0.9637, 0.9618],\n",
            "        [0.9681, 0.9634, 0.9581]], grad_fn=<MmBackward0>)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/home/saurabh/anaconda3/envs/lighting/lib/python3.8/site-packages/torch/nn/modules/rnn.py:67: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.25 and num_layers=1\n",
            "  warnings.warn(\"dropout option adds dropout after all but last \"\n"
          ]
        }
      ],
      "source": [
        "## test model architecture\n",
        "model = SiameseModel(len(vocab), emb_dim = 100, hidden_dim = 150, margin = 0.25, threshold = 0.7, learning_rate = 1e-3,\n",
        "                     bidirectional= False, num_layers = 1, dropout = 0.25, use_pretrained = False)\n",
        "print(model)\n",
        "q1, q2, q1_lengths, q2_lengths = example['q1'], example['q2'],example['q1_lengths'],example['q2_lengths']\n",
        "v1,v2 = model(q1, q2, q1_lengths, q2_lengths)\n",
        "scores = torch.matmul(v1,v2.T)\n",
        "loss = model.loss_fn(scores)\n",
        "print(loss)\n",
        "print(scores)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GTd2_rk9Aw0q",
        "outputId": "563334c0-648a-4b7c-c8ce-7724286f2ae8",
        "colab": {
          "referenced_widgets": [
            "87b26d246e2940bfa2fb1115be82c22b",
            "7f3ed243dd394c0b8852f54139e7f959",
            "11e6490dc1f24e2aa29f52538be25de4",
            "9ebee703cdd74e599780dbefce9f6b21",
            "43cf0cc3bb6a453d969cff3188795b7b",
            "557103f5490f416cac9634171cb65911",
            "a9dab1fbd0414e1586efed0f549c761c"
          ]
        }
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/home/saurabh/anaconda3/envs/lighting/lib/python3.8/site-packages/torch/nn/modules/rnn.py:67: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.5 and num_layers=1\n",
            "  warnings.warn(\"dropout option adds dropout after all but last \"\n",
            "GPU available: True (cuda), used: True\n",
            "TPU available: False, using: 0 TPU cores\n",
            "IPU available: False, using: 0 IPUs\n",
            "HPU available: False, using: 0 HPUs\n",
            "/home/saurabh/anaconda3/envs/lighting/lib/python3.8/site-packages/pytorch_lightning/trainer/connectors/logger_connector/logger_connector.py:67: Starting from v1.9.0, `tensorboardX` has been removed as a dependency of the `pytorch_lightning` package, due to potential conflicts with other packages in the ML ecosystem. For this reason, `logger=True` will use `CSVLogger` as the default logger, unless the `tensorboard` or `tensorboardX` packages are found. Please `pip install lightning[extra]` or one of them to enable TensorBoard support by default\n",
            "/home/saurabh/anaconda3/envs/lighting/lib/python3.8/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:639: Checkpoint directory /home/saurabh/mydata/checkpoints_logs exists and is not empty.\n",
            "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [1]\n",
            "\n",
            "  | Name      | Type      | Params\n",
            "----------------------------------------\n",
            "0 | embedding | Embedding | 3.5 M \n",
            "1 | lstm      | LSTM      | 151 K \n",
            "2 | linear    | Linear    | 22.7 K\n",
            "3 | relu      | ReLU      | 0     \n",
            "----------------------------------------\n",
            "3.7 M     Trainable params\n",
            "0         Non-trainable params\n",
            "3.7 M     Total params\n",
            "14.811    Total estimated model params size (MB)\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "87b26d246e2940bfa2fb1115be82c22b",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Sanity Checking: |          | 0/? [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/home/saurabh/anaconda3/envs/lighting/lib/python3.8/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:441: The 'val_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=15` in the `DataLoader` to improve performance.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Current Epoch : 0 Valiadtion Loss : 0.49436189234256744\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/home/saurabh/anaconda3/envs/lighting/lib/python3.8/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:441: The 'train_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=15` in the `DataLoader` to improve performance.\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "7f3ed243dd394c0b8852f54139e7f959",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Training: |          | 0/? [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "11e6490dc1f24e2aa29f52538be25de4",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Validation: |          | 0/? [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Current Epoch : 0 Valiadtion Loss : 0.2566767697721594\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "9ebee703cdd74e599780dbefce9f6b21",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Validation: |          | 0/? [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Current Epoch : 1 Valiadtion Loss : 0.2353735192038339\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "43cf0cc3bb6a453d969cff3188795b7b",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Validation: |          | 0/? [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Current Epoch : 2 Valiadtion Loss : 0.22896539784559217\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "557103f5490f416cac9634171cb65911",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Validation: |          | 0/? [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Current Epoch : 3 Valiadtion Loss : 0.22397989572226246\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "a9dab1fbd0414e1586efed0f549c761c",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Validation: |          | 0/? [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "`Trainer.fit` stopped: `max_epochs=5` reached.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Current Epoch : 4 Valiadtion Loss : 0.22066892089345788\n"
          ]
        }
      ],
      "source": [
        "## Model Training\n",
        "model= SiameseModel(len(vocab), emb_dim = 100, hidden_dim = 150, margin = 0.25, threshold = 0.7,\n",
        "                    learning_rate = 1e-3, bidirectional= False, num_layers = 1, dropout = 0.5,use_pretrained = False)\n",
        "\n",
        "callbacks = pl.callbacks.ModelCheckpoint(dirpath = \"checkpoints_logs\",\n",
        "                                         filename = '{epoch}-{val_loss:.2f}',\n",
        "                                          mode = \"min\",\n",
        "                                          monitor = \"val_loss\",\n",
        "                                          save_last = True,\n",
        "                                          save_top_k=-1)\n",
        "\n",
        "\n",
        "trainer = pl.Trainer(accelerator= \"gpu\",\n",
        "           max_epochs=5,\n",
        "           check_val_every_n_epoch = 1,\n",
        "           callbacks = [callbacks])\n",
        "\n",
        "trainer.fit(model, train_dl, val_dl)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "h3RNEbNlAw0q"
      },
      "source": [
        "## Test the accuracy"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-C8U5I7vAw0q",
        "outputId": "f87a1f1b-91b7-4a49-d424-0bf12152be18",
        "colab": {
          "referenced_widgets": [
            "ea167c8b94f6483388f19ba5e75e59d0"
          ]
        }
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/tmp/ipykernel_28305/1800247455.py:13: TqdmDeprecationWarning: This function will be removed in tqdm==5.0.0\n",
            "Please use `tqdm.notebook.tqdm` instead of `tqdm.tqdm_notebook`\n",
            "  for batch in tqdm_notebook(val_dl):\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "ea167c8b94f6483388f19ba5e75e59d0",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "  0%|          | 0/474 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Test Accuracy : 0.7442397263097151\n"
          ]
        }
      ],
      "source": [
        "model = model.eval()\n",
        "\n",
        "total = 0\n",
        "correct = 0\n",
        "total = 0\n",
        "threshold = 0.7\n",
        "y_pred_list = []\n",
        "y_true_list = []\n",
        "device = \"cuda\"\n",
        "\n",
        "model.to(device)\n",
        "\n",
        "for batch in tqdm_notebook(val_dl):\n",
        "    q1,q2, q1_lengths, q2_lengths = batch['q1'], batch['q2'],batch['q1_lengths'], batch['q2_lengths']\n",
        "    batch_size = q1.shape[0]\n",
        "\n",
        "    q1 = q1.to(device)\n",
        "    q2 = q2.to(device)\n",
        "    v1,v2 = model(q1,q2,q1_lengths, q2_lengths)\n",
        "    v1.to(device)\n",
        "    v2.to(device)\n",
        "    scores = torch.matmul(v1, v2.T)\n",
        "    res = torch.diag(scores)\n",
        "    y_pred = (res>threshold).long()\n",
        "    y_pred = y_pred.cpu().numpy()\n",
        "    y_true = torch.tensor(y_test[total: total + batch_size])\n",
        "    y_true = y_true.cpu().numpy()\n",
        "\n",
        "    y_pred_list += list(y_pred)\n",
        "    y_true_list += list(y_true)\n",
        "    correct += sum(y_true == y_pred)\n",
        "    total += len(y_pred)\n",
        "\n",
        "print(f\"Test Accuracy : {correct/total}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-POzrswcAw0r",
        "outputId": "182943b6-3a4e-48ee-bddb-1446fbd59a21"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.85      0.73      0.78     76513\n",
            "           1       0.62      0.77      0.69     44792\n",
            "\n",
            "    accuracy                           0.74    121305\n",
            "   macro avg       0.73      0.75      0.74    121305\n",
            "weighted avg       0.76      0.74      0.75    121305\n",
            "\n"
          ]
        }
      ],
      "source": [
        "print(classification_report(y_true_list, y_pred_list))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ERMZbRPyAw0r",
        "outputId": "586ca2f5-10d7-4dcb-a6f0-f08bce8c8265"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[[55608 20905]\n",
            " [10120 34672]]\n"
          ]
        }
      ],
      "source": [
        "print(confusion_matrix(y_true=y_true_list, y_pred = y_pred_list))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xVsfakGIAw0r"
      },
      "source": [
        "## Predict"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jSOFAX2lAw0s"
      },
      "outputs": [],
      "source": [
        "model = model.eval()\n",
        "model.to(\"cpu\")\n",
        "\n",
        "def predict(q1, q2, threshold = 0.7):\n",
        "\n",
        "    q1_words = tokenize.word_tokenize(q1)\n",
        "    q2_words = tokenize.word_tokenize(q2)\n",
        "\n",
        "    q1_encoded = [vocab.get(w, UNK_ID) for w in q1_words]\n",
        "    q2_encoded = [vocab.get(w, UNK_ID) for w in q2_words]\n",
        "\n",
        "    q1_len = len(q1_encoded)\n",
        "    q2_len = len(q2_encoded)\n",
        "\n",
        "    q1 = torch.tensor(q1_encoded).view(1,-1)\n",
        "    q2 = torch.tensor(q2_encoded).view(1,-1)\n",
        "\n",
        "    q1_lengths = torch.tensor([q1.shape[1]], dtype = torch.long)\n",
        "    q2_lengths = torch.tensor([q2.shape[1]], dtype = torch.long)\n",
        "\n",
        "    v1, v2 = model(q1, q2, q1_lengths, q2_lengths)\n",
        "    score = torch.matmul(v1, v2.T)\n",
        "    if score > threshold:\n",
        "        return (\"Duplicated\", score.item())\n",
        "    else:\n",
        "        return (\"Not Duplicated\", score.item())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VHyrSZ2vAw0s",
        "outputId": "d720436e-2a2b-408a-bff5-e81d9a24d740"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "('Duplicated', 0.7624601125717163)"
            ]
          },
          "execution_count": 30,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "question1 = \"When will I see you?\"\n",
        "question2 = \"When can I see you again?\"\n",
        "predict(question1 , question2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IBoOx9EIAw0s",
        "outputId": "4d10f80d-5141-42a2-dfdf-7f434d344e63"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "('Not Duplicated', 0.24493733048439026)"
            ]
          },
          "execution_count": 31,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "question1 = \"Do they enjoy eating the dessert?\"\n",
        "question2 = \"Do they like hiking in the desert?\"\n",
        "predict(question1 , question2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2CbDWxe6Aw0s"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "lighting",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.18"
    },
    "colab": {
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}