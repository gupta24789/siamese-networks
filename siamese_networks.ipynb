{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/gupta24789/siamese-networks/blob/main/siamese_networks.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7Oc1Jy2_Qqfp"
      },
      "outputs": [],
      "source": [
        "# !wget https://github.com/gupta24789/siamese-networks/raw/main/data.zip\n",
        "# !unzip data.zip"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cakjRdAeQqfs"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "os.environ['CUDA_VISIBLE_DEVICES'] = \"1\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nPY2I8K6Qqft"
      },
      "outputs": [],
      "source": [
        "import random\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import itertools\n",
        "from nltk import tokenize\n",
        "from tqdm import tqdm, tqdm_notebook\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "from torch.nn.utils.rnn import pad_sequence, pack_padded_sequence\n",
        "from torch.utils.data import DataLoader, Dataset\n",
        "\n",
        "\n",
        "import pytorch_lightning as pl"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9-0ifnbsQqft"
      },
      "source": [
        "## Set Seed"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QLoT27MoQqfv",
        "outputId": "7b1dcd91-935e-4cb9-f26e-faa619f9730d"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Seed set to 34\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "34"
            ]
          },
          "execution_count": 4,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "seed = 34\n",
        "random.seed(seed)\n",
        "torch.manual_seed(seed)\n",
        "pl.seed_everything(seed)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "z3nPZ07NQqfx"
      },
      "source": [
        "## Read Data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lo-FwL2tQqfx",
        "outputId": "6043b013-d2d9-432f-a25b-70664d8a3377"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "train shape : (283045, 6)\n",
            "test shape : (121305, 6)\n"
          ]
        }
      ],
      "source": [
        "train_df = pd.read_csv(\"data/train.csv\")\n",
        "test_df = pd.read_csv(\"data/test.csv\")\n",
        "test_df = test_df.dropna().reset_index(drop = True)\n",
        "\n",
        "print(f'train shape : {train_df.shape}')\n",
        "print(f'test shape : {test_df.shape}')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5iNCP6LHQqfy",
        "outputId": "88a91168-bbf7-4590-98f7-ddc1b454cf9f"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>qid1</th>\n",
              "      <th>qid2</th>\n",
              "      <th>question1</th>\n",
              "      <th>question2</th>\n",
              "      <th>is_duplicate</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>27186</td>\n",
              "      <td>54210</td>\n",
              "      <td>54211</td>\n",
              "      <td>What will happen if Google starts charging for...</td>\n",
              "      <td>Is it normal to Google search every question y...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>246439</td>\n",
              "      <td>485308</td>\n",
              "      <td>485309</td>\n",
              "      <td>Why are bats associated with vampires?</td>\n",
              "      <td>Do vampires get periods?</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>298392</td>\n",
              "      <td>586093</td>\n",
              "      <td>586094</td>\n",
              "      <td>How can I start learning data science?</td>\n",
              "      <td>How can I start learning data science and beco...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "       id    qid1    qid2                                          question1  \\\n",
              "0   27186   54210   54211  What will happen if Google starts charging for...   \n",
              "1  246439  485308  485309             Why are bats associated with vampires?   \n",
              "2  298392  586093  586094             How can I start learning data science?   \n",
              "\n",
              "                                           question2  is_duplicate  \n",
              "0  Is it normal to Google search every question y...             0  \n",
              "1                           Do vampires get periods?             0  \n",
              "2  How can I start learning data science and beco...             1  "
            ]
          },
          "execution_count": 7,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "train_df.head(3)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "M2K8ML28Qqfy",
        "outputId": "da744cec-6f90-4ee0-a9e8-023deef54ca8"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>qid1</th>\n",
              "      <th>qid2</th>\n",
              "      <th>question1</th>\n",
              "      <th>question2</th>\n",
              "      <th>is_duplicate</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>291513</td>\n",
              "      <td>572739</td>\n",
              "      <td>572740</td>\n",
              "      <td>What Rolling Stone song has the lyrics “oh and...</td>\n",
              "      <td>What's the point in living if you're so depres...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>58652</td>\n",
              "      <td>116675</td>\n",
              "      <td>76915</td>\n",
              "      <td>Do you have a Business-Plan to help the poor p...</td>\n",
              "      <td>Suppose you run a mobile business which genera...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>118294</td>\n",
              "      <td>139357</td>\n",
              "      <td>234460</td>\n",
              "      <td>Where's a good university to study Computer Sc...</td>\n",
              "      <td>What are some good UK universities in computer...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "       id    qid1    qid2                                          question1  \\\n",
              "0  291513  572739  572740  What Rolling Stone song has the lyrics “oh and...   \n",
              "1   58652  116675   76915  Do you have a Business-Plan to help the poor p...   \n",
              "2  118294  139357  234460  Where's a good university to study Computer Sc...   \n",
              "\n",
              "                                           question2  is_duplicate  \n",
              "0  What's the point in living if you're so depres...             0  \n",
              "1  Suppose you run a mobile business which genera...             0  \n",
              "2  What are some good UK universities in computer...             1  "
            ]
          },
          "execution_count": 8,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "test_df.head(3)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Yq2SFYV0Qqfy"
      },
      "source": [
        "## Prepare Data\n",
        "\n",
        "\n",
        "The data is setup so that $v_{1\\_1}$ and $v_{2\\_1}$ represent duplicate inputs, but they are not duplicates with any other rows in the batch. This means $v_{1\\_1}$ and $v_{2\\_1}$ (green and green) have more similar vectors than say $v_{1\\_1}$ and $v_{2\\_2}$ (green and magenta).\n",
        "\n",
        "<img src = 'images/v1v2_stacked.png' width=\"width\" height=\"height\" style=\"height:250px;\"/>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "n-zGx9epQqfz"
      },
      "outputs": [],
      "source": [
        "## Create vocab using duplicates questions only\n",
        "Q1_train_sents = train_df.loc[train_df.is_duplicate==1,'question1'].tolist()\n",
        "Q2_train_sents = train_df.loc[train_df.is_duplicate==1,'question2'].tolist()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FiEoB0feQqfz",
        "outputId": "a3a0c1a0-334a-47e0-c071-2ac16b8c8fa8"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "['How can I start learning data science?',\n",
              " 'Which is the best book to understand tensors?',\n",
              " 'Who viewed my profile on Instagram?']"
            ]
          },
          "execution_count": 10,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "Q1_train_sents[:3]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "p_8N4I7tQqf0",
        "outputId": "d6d0519c-8bcb-4368-daed-e809901786d8"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "['How can I start learning data science and become master in it?',\n",
              " 'Which is the best book to study TENSOR for general relativity from basic?',\n",
              " 'Can people see if you have viewed their instagram?']"
            ]
          },
          "execution_count": 11,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "Q2_train_sents[:3]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1vkliyYUQqf0",
        "outputId": "108ef120-470c-47ee-c812-ecd3d22fa2af"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Vocab 35289\n",
            "PAD ID : 0\n",
            "UNK ID : 1\n"
          ]
        }
      ],
      "source": [
        "## merge q1 & q2\n",
        "train_sents = Q1_train_sents + Q2_train_sents\n",
        "tokens = [tokenize.word_tokenize(sent) for sent in train_sents]\n",
        "tokens = list(set(itertools.chain.from_iterable(tokens)))\n",
        "\n",
        "special_tokens = ['__PAD__', '__UNK__']\n",
        "tokens = special_tokens + tokens\n",
        "\n",
        "vocab = {w:i for i,w in enumerate(tokens)}\n",
        "idx2word = {i:w for w,i in vocab.items()}\n",
        "\n",
        "UNK_ID = vocab['__UNK__']\n",
        "PAD_ID = vocab['__PAD__']\n",
        "\n",
        "print(f\"Vocab {len(vocab)}\")\n",
        "print(f\"PAD ID : {PAD_ID}\")\n",
        "print(f\"UNK ID : {UNK_ID}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wNWOiGAFQqf0"
      },
      "outputs": [],
      "source": [
        "def encode_sent_to_number(sent):\n",
        "    sent_list = tokenize.word_tokenize(sent)\n",
        "    encoded_sent = []\n",
        "\n",
        "    for w in sent_list:\n",
        "        encoded_sent.append(vocab.get(w, UNK_ID))\n",
        "\n",
        "    return encoded_sent"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Q2Vres3PQqf0"
      },
      "outputs": [],
      "source": [
        "Q1_train_encoded = [encode_sent_to_number(sent) for sent in Q1_train_sents]\n",
        "Q2_train_encoded = [encode_sent_to_number(sent) for sent in Q2_train_sents]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YWUx_P7pQqf1"
      },
      "outputs": [],
      "source": [
        "Q1_test_encoded = [encode_sent_to_number(sent) for sent in test_df.question1.tolist()]\n",
        "Q2_test_encoded = [encode_sent_to_number(sent) for sent in test_df.question2.tolist()]\n",
        "y_test = test_df.is_duplicate.tolist()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dR-QT2vLQqf1"
      },
      "source": [
        "## Data Loader"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Z5PMXcV7Qqf1"
      },
      "outputs": [],
      "source": [
        "def custom_collate(batch):\n",
        "\n",
        "    q1 = [torch.tensor(item[0]) for item in batch]\n",
        "    q1_lengths = torch.tensor([len(item[0]) for item in batch] )\n",
        "\n",
        "\n",
        "    q2 = [torch.tensor(item[1]) for item in batch]\n",
        "    q2_lengths = torch.tensor([len(item[1]) for item in batch])\n",
        "\n",
        "    padded_q1 = pad_sequence(q1, batch_first= True, padding_value= PAD_ID)\n",
        "    padded_q2 = pad_sequence(q2, batch_first= True, padding_value= PAD_ID)\n",
        "\n",
        "    batch = {\"q1\": padded_q1, \"q2\": padded_q2,\"q1_lengths\": q1_lengths, \"q2_lengths\": q2_lengths}\n",
        "    return batch"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SVZvvD9KQqf1",
        "outputId": "1d52628d-5f03-43e7-d016-c36704f7f389"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(torch.Size([3, 9]), torch.Size([3, 14]), torch.Size([3]), torch.Size([3]))"
            ]
          },
          "execution_count": 19,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "batch_size = 3\n",
        "train_dl = DataLoader(list(zip(Q1_train_encoded,Q2_train_encoded)), batch_size = batch_size, shuffle=False, collate_fn= custom_collate)\n",
        "example = next(iter(train_dl))\n",
        "example['q1'].shape, example['q2'].shape, example['q1_lengths'].shape, example['q2_lengths'].shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0AaRxFLAQqf1",
        "outputId": "6e807a7f-e456-417e-8351-24a670b5fa3c"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "tensor([[10099, 28674, 10107, 28501,  6615,  9219, 28539, 25610,     0],\n",
              "        [21715, 21347, 32108,  4871, 24280,  1962, 11812,  6551, 25610],\n",
              "        [18090, 28904, 12971, 25354,  3562, 12178, 25610,     0,     0]])"
            ]
          },
          "execution_count": 20,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "example['q1']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rnx7LmyuQqf1",
        "outputId": "fda35f5b-a515-433f-93b5-d036672bedc3"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "tensor([8, 9, 7])"
            ]
          },
          "execution_count": 21,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "example['q1_lengths']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3MXDCkxKQqf2"
      },
      "outputs": [],
      "source": [
        "## dataloaders\n",
        "batch_size = 256\n",
        "train_dl = DataLoader(list(zip(Q1_train_encoded,Q2_train_encoded)), batch_size = batch_size, shuffle=True, collate_fn= custom_collate)\n",
        "val_dl = DataLoader(list(zip(Q1_test_encoded,Q2_test_encoded)), batch_size = batch_size, shuffle=False, collate_fn= custom_collate)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hSuZ0UoZQqf2"
      },
      "source": [
        "## Model\n",
        "\n",
        "You will now implement the `TripletLoss`.<br>\n",
        "As explained in the lecture, loss is composed of two terms. One term utilizes the mean of all the non duplicates, the second utilizes the *closest negative*. Our loss expression is then:\n",
        "\n",
        "\\begin{align}\n",
        " \\mathcal{Loss_1(A,P,N)} &=\\max \\left( -cos(A,P)  + mean_{neg} +\\alpha, 0\\right) \\\\\n",
        " \\mathcal{Loss_2(A,P,N)} &=\\max \\left( -cos(A,P)  + closest_{neg} +\\alpha, 0\\right) \\\\\n",
        "\\mathcal{Loss(A,P,N)} &= mean(Loss_1 + Loss_2) \\\\\n",
        "\\end{align}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Dp08acoAQqf2"
      },
      "outputs": [],
      "source": [
        "class SiameseModel(pl.LightningModule):\n",
        "\n",
        "    def __init__(self, vocab_size, emb_dim, hidden_dim, margin, threshold, learning_rate, bidirectional, dropout, num_layers):\n",
        "        super().__init__()\n",
        "        self.bidirectional = bidirectional\n",
        "        self.learning_rate = learning_rate\n",
        "        self.margin = margin\n",
        "        self.threhold = threshold\n",
        "        self.val_loss = []\n",
        "\n",
        "        # layers\n",
        "        self.embedding = nn.Embedding(vocab_size, emb_dim, padding_idx=PAD_ID)\n",
        "        self.lstm = nn.LSTM(emb_dim, hidden_dim, batch_first = True, num_layers = num_layers, bidirectional = bidirectional, dropout = dropout)\n",
        "\n",
        "    def loss_fn(self, scores):\n",
        "\n",
        "        device = \"cuda\" if scores.is_cuda else \"cpu\"\n",
        "        batch_size = len(scores)\n",
        "        positive = torch.diagonal(scores)\n",
        "        negative_zero_on_duplicate = scores * (1.0 - torch.eye(batch_size)).to(device)\n",
        "        mean_negative = torch.sum(negative_zero_on_duplicate, axis=1) / (batch_size-1)\n",
        "\n",
        "        negative_without_positive = scores - 2.0 * torch.eye(batch_size).to(device)\n",
        "        closest_negative, _ = negative_without_positive.max(axis=1)\n",
        "\n",
        "        # print(f\"scores : \\n{scores}\")\n",
        "        # print(\"positive : \", positive)\n",
        "        # print(f\"neg : {negative_zero_on_duplicate}\")\n",
        "        # print(\"mean_negative : \", mean_negative)\n",
        "        # print(\"closest_negative : \", closest_negative)\n",
        "\n",
        "        triplet_loss1 = torch.maximum(torch.tensor(0.0), self.margin - positive + closest_negative)\n",
        "        triplet_loss2 = torch.maximum(torch.tensor(0.0), self.margin - positive + mean_negative)\n",
        "        triplet_loss = torch.mean(triplet_loss1 + triplet_loss2)\n",
        "        return triplet_loss\n",
        "\n",
        "    def get_normalize_vector(self, q, q_lengths):\n",
        "        out = self.embedding(q)\n",
        "        ## out : [batch size, sent len, emb dim]\n",
        "        packed_input = pack_padded_sequence(out, lengths= q_lengths.to('cpu'), batch_first = True, enforce_sorted=False)\n",
        "        packed_output, (hidden, cell) = self.lstm(packed_input)\n",
        "        out, output_lengths = nn.utils.rnn.pad_packed_sequence(packed_output, batch_first = True)\n",
        "        ## out : [batch size, sent len, hidden dim * bidirectional]\n",
        "        # hidden : [num_layers * bidirectional, batch size,hidden dim]\n",
        "\n",
        "        # out = torch.cat((hidden[-2,:,:], hidden[-1,:,:]), dim = 1)\n",
        "        ## out : [batch size, hidden_dim * bidirectional]\n",
        "        out = torch.mean(out, dim = 1)\n",
        "        ## [batch size, hidden dim * bidirectional]\n",
        "        out = F.normalize(out, p = 2)\n",
        "\n",
        "        return out\n",
        "\n",
        "    def forward(self, q1, q2, q1_lengths, q2_lengths):\n",
        "        q1_vec = self.get_normalize_vector(q1, q1_lengths)\n",
        "        # print(q1_vec.shape)\n",
        "        q2_vec = self.get_normalize_vector(q2, q2_lengths)\n",
        "        # print(q2_vec.shape)\n",
        "        return (q1_vec, q2_vec)\n",
        "\n",
        "    def training_step(self, batch):\n",
        "        q1,q2,q1_lengths, q2_lengths = batch['q1'], batch['q2'],batch['q1_lengths'], batch['q2_lengths']\n",
        "        q1_vec,q2_vec = self(q1,q2,q1_lengths, q2_lengths)\n",
        "        scores = torch.matmul(q1_vec, q2_vec.T)\n",
        "        loss = self.loss_fn(scores)\n",
        "        self.log_dict({\"train_loss\": loss}, on_step = False, on_epoch = True, prog_bar=True)\n",
        "        return loss\n",
        "\n",
        "    def validation_step(self, batch):\n",
        "        q1,q2,q1_lengths, q2_lengths = batch['q1'], batch['q2'],batch['q1_lengths'], batch['q2_lengths']\n",
        "        q1_vec,q2_vec = self(q1,q2,q1_lengths, q2_lengths)\n",
        "        scores = torch.matmul(q1_vec, q2_vec.T)\n",
        "        loss = self.loss_fn(scores)\n",
        "        self.val_loss.append(loss.item())\n",
        "        self.log_dict({\"val_loss\": loss}, on_step = False, on_epoch = True, prog_bar=True)\n",
        "        return loss\n",
        "\n",
        "    def on_validation_epoch_end(self):\n",
        "        print(f\"Current Epoch : {self.current_epoch} Valiadtion Loss : {np.mean(self.val_loss)}\")\n",
        "        self.val_loss = []\n",
        "\n",
        "    def configure_optimizers(self):\n",
        "        optimizer = optim.Adam(self.parameters(), lr = self.learning_rate)\n",
        "        return optimizer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4PoaBHZAQqf2",
        "outputId": "31967ebe-bade-4c15-c5ba-da5dc3c47eb7"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "SiameseModel(\n",
            "  (embedding): Embedding(35289, 100, padding_idx=0)\n",
            "  (lstm): LSTM(100, 150, num_layers=2, batch_first=True, dropout=0.25, bidirectional=True)\n",
            ")\n",
            "tensor(0.3421, grad_fn=<MeanBackward0>)\n",
            "tensor([[0.8784, 0.6379, 0.6515],\n",
            "        [0.7014, 0.7593, 0.6195],\n",
            "        [0.7021, 0.6844, 0.6259]], grad_fn=<MmBackward0>)\n"
          ]
        }
      ],
      "source": [
        "## test model architecture\n",
        "model = SiameseModel(len(vocab), emb_dim = 100, hidden_dim = 150, margin = 0.25, threshold = 0.7, learning_rate = 1e-3, bidirectional= True, num_layers = 2, dropout = 0.25)\n",
        "print(model)\n",
        "q1, q2, q1_lengths, q2_lengths = example['q1'], example['q2'],example['q1_lengths'],example['q2_lengths']\n",
        "v1,v2 = model(q1, q2, q1_lengths, q2_lengths)\n",
        "scores = torch.matmul(v1,v2.T)\n",
        "loss = model.loss_fn(scores)\n",
        "print(loss)\n",
        "print(scores)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "osQs4ihkQqf2",
        "outputId": "6a9da5ee-1d7a-4e1c-ca22-b6e553e6edf6",
        "colab": {
          "referenced_widgets": [
            "86befe1a2ed6400b9da26656974841de",
            "09248a92ad9f4753a4463c029128f0a0",
            "5aaa16ecf79c4f2e96ba8f657d03a054",
            "2a15cd4bd20f44519b2036629730a8df",
            "095490171c494f70be4cabc91a167502",
            "fb5d16888cb2439b97ec0c995da04e7a",
            "87484335f57f48deba4c76540cd484b9",
            "d575f1a6a5584cd28a4bae20e308293b",
            "fb2b36a48a9c4ebfa2ab3b5a9ee64b4a",
            "d8bc4e26391c48ffbc66dbdcb930b411",
            "b0dc0b13f97f4b27a2ea4a18a0454b2f",
            "a0d22674ce734d2a962ed8bd8ceb89fe"
          ]
        }
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "GPU available: True (cuda), used: True\n",
            "TPU available: False, using: 0 TPU cores\n",
            "IPU available: False, using: 0 IPUs\n",
            "HPU available: False, using: 0 HPUs\n",
            "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [1]\n",
            "\n",
            "  | Name      | Type      | Params\n",
            "----------------------------------------\n",
            "0 | embedding | Embedding | 3.5 M \n",
            "1 | lstm      | LSTM      | 844 K \n",
            "----------------------------------------\n",
            "4.4 M     Trainable params\n",
            "0         Non-trainable params\n",
            "4.4 M     Total params\n",
            "17.495    Total estimated model params size (MB)\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "86befe1a2ed6400b9da26656974841de",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Sanity Checking: |          | 0/? [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Current Epoch : 0 Valiadtion Loss : 0.39718714356422424\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "09248a92ad9f4753a4463c029128f0a0",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Training: |          | 0/? [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "5aaa16ecf79c4f2e96ba8f657d03a054",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Validation: |          | 0/? [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Current Epoch : 0 Valiadtion Loss : 0.22610070188588735\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "2a15cd4bd20f44519b2036629730a8df",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Validation: |          | 0/? [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Current Epoch : 1 Valiadtion Loss : 0.2174533960499844\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "095490171c494f70be4cabc91a167502",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Validation: |          | 0/? [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Current Epoch : 2 Valiadtion Loss : 0.20873566804933147\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "fb5d16888cb2439b97ec0c995da04e7a",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Validation: |          | 0/? [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Current Epoch : 3 Valiadtion Loss : 0.20514547372166114\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "87484335f57f48deba4c76540cd484b9",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Validation: |          | 0/? [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Current Epoch : 4 Valiadtion Loss : 0.20317663019719506\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "d575f1a6a5584cd28a4bae20e308293b",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Validation: |          | 0/? [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Current Epoch : 5 Valiadtion Loss : 0.20242489578854686\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "fb2b36a48a9c4ebfa2ab3b5a9ee64b4a",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Validation: |          | 0/? [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Current Epoch : 6 Valiadtion Loss : 0.20391115587094666\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "d8bc4e26391c48ffbc66dbdcb930b411",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Validation: |          | 0/? [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Current Epoch : 7 Valiadtion Loss : 0.20404893643996885\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "b0dc0b13f97f4b27a2ea4a18a0454b2f",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Validation: |          | 0/? [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Current Epoch : 8 Valiadtion Loss : 0.20134402858682826\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "a0d22674ce734d2a962ed8bd8ceb89fe",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Validation: |          | 0/? [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "`Trainer.fit` stopped: `max_epochs=10` reached.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Current Epoch : 9 Valiadtion Loss : 0.2016061165287525\n"
          ]
        }
      ],
      "source": [
        "## Model Training\n",
        "model= SiameseModel(len(vocab), emb_dim = 100, hidden_dim = 150, margin = 0.25, threshold = 0.7, learning_rate = 1e-3, bidirectional= True, num_layers = 2, dropout = 0.1)\n",
        "\n",
        "callbacks = pl.callbacks.ModelCheckpoint(dirpath = \"checkpoints_logs\",\n",
        "                                         filename = '{epoch}-{val_loss:.2f}',\n",
        "                                          mode = \"min\",\n",
        "                                          monitor = \"val_loss\",\n",
        "                                          save_last = True,\n",
        "                                          save_top_k=-1)\n",
        "\n",
        "\n",
        "trainer = pl.Trainer(accelerator= \"gpu\",\n",
        "           max_epochs=10,\n",
        "           check_val_every_n_epoch = 1,\n",
        "           callbacks = [callbacks])\n",
        "\n",
        "trainer.fit(model, train_dl, val_dl)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5aSXiqPjQqf3"
      },
      "source": [
        "## Test the accuracy"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "T6DthqI9Qqf3",
        "outputId": "222710a6-b2e9-4e2d-dbec-e1cb3a425449",
        "colab": {
          "referenced_widgets": [
            "50f3a401401b43c9a6f93011ea52111d"
          ]
        }
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/tmp/ipykernel_3694/4028790655.py:11: TqdmDeprecationWarning: This function will be removed in tqdm==5.0.0\n",
            "Please use `tqdm.notebook.tqdm` instead of `tqdm.tqdm_notebook`\n",
            "  for batch in tqdm_notebook(val_dl):\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "50f3a401401b43c9a6f93011ea52111d",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "  0%|          | 0/474 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Test Accuracy : 0.7192448786117638\n"
          ]
        }
      ],
      "source": [
        "model = model.eval()\n",
        "\n",
        "total = 0\n",
        "correct = 0\n",
        "total = 0\n",
        "threshold = 0.7\n",
        "device = \"cuda\"\n",
        "\n",
        "model.to(device)\n",
        "\n",
        "for batch in tqdm_notebook(val_dl):\n",
        "    q1,q2, q1_lengths, q2_lengths = batch['q1'], batch['q2'],batch['q1_lengths'], batch['q2_lengths']\n",
        "    batch_size = q1.shape[0]\n",
        "\n",
        "    q1 = q1.to(device)\n",
        "    q2 = q2.to(device)\n",
        "    v1,v2 = model(q1,q2,q1_lengths, q2_lengths)\n",
        "    v1.to(device)\n",
        "    v2.to(device)\n",
        "    scores = torch.matmul(v1, v2.T)\n",
        "    res = torch.diag(scores)\n",
        "    y_pred = (res>threshold).long()\n",
        "    y_true = torch.tensor(y_test[total: total + batch_size])\n",
        "\n",
        "    correct += sum(y_true == y_pred.cpu()).item()\n",
        "    total += len(y_pred)\n",
        "\n",
        "print(f\"Test Accuracy : {correct/total}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zwjKWSzIQqf3"
      },
      "source": [
        "## Predict"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iKp4qOdNQqf3"
      },
      "outputs": [],
      "source": [
        "model = model.eval()\n",
        "model.to(\"cpu\")\n",
        "\n",
        "def predict(q1, q2, threshold = 0.7):\n",
        "\n",
        "    q1_words = tokenize.word_tokenize(q1)\n",
        "    q2_words = tokenize.word_tokenize(q2)\n",
        "\n",
        "    q1_encoded = [vocab.get(w, UNK_ID) for w in q1_words]\n",
        "    q2_encoded = [vocab.get(w, UNK_ID) for w in q2_words]\n",
        "\n",
        "    q1_len = len(q1_encoded)\n",
        "    q2_len = len(q2_encoded)\n",
        "\n",
        "    q1 = torch.tensor(q1_encoded).view(1,-1)\n",
        "    q2 = torch.tensor(q2_encoded).view(1,-1)\n",
        "\n",
        "    q1_lengths = torch.tensor([q1.shape[1]], dtype = torch.long)\n",
        "    q2_lengths = torch.tensor([q2.shape[1]], dtype = torch.long)\n",
        "\n",
        "    v1, v2 = model(q1,q2, q1_lengths, q2_lengths)\n",
        "    score = torch.matmul(v1, v2.T)\n",
        "    if score > threshold:\n",
        "        return (\"Duplicated\", score.item())\n",
        "    else:\n",
        "        return (\"Not Duplicated\", score.item())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zuWolMNDQqf3",
        "outputId": "3cad12f5-b0bc-40d2-b4a6-a236ac97d155"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "('Duplicated', 0.7735307216644287)"
            ]
          },
          "execution_count": 40,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "question1 = \"When will I see you?\"\n",
        "question2 = \"When can I see you again?\"\n",
        "predict(question1 , question2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pwo_F8ocQqf3",
        "outputId": "fdf00393-9c3b-45a9-ff89-6dc70cebc872"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "('Not Duplicated', 0.14368796348571777)"
            ]
          },
          "execution_count": 41,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "question1 = \"Do they enjoy eating the dessert?\"\n",
        "question2 = \"Do they like hiking in the desert?\"\n",
        "predict(question1 , question2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "D8D4bhdcQqf4"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "lighting",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.18"
    },
    "colab": {
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}