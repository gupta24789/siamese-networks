{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/gupta24789/siamese-networks/blob/main/triplet_loss.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aM5Ro2DUtuIh"
      },
      "source": [
        "## Triplet Loss\n",
        "\n",
        "This is the original triplet loss function:\n",
        "\n",
        "$\\mathcal{L_\\mathrm{Original}} = \\max{(\\mathrm{s}(A,N) -\\mathrm{s}(A,P) +\\alpha, 0)}$\n",
        "\n",
        "It can be improved by including the mean negative and the closest negative, to create a new full loss function. The inputs are the Anchor $\\mathrm{A}$, Positive $\\mathrm{P}$ and Negative $\\mathrm{N}$.\n",
        "\n",
        "$\\mathcal{L_\\mathrm{1}} = \\max{(mean\\_neg -\\mathrm{s}(A,P)  +\\alpha, 0)}$\n",
        "\n",
        "$\\mathcal{L_\\mathrm{2}} = \\max{(closest\\_neg -\\mathrm{s}(A,P)  +\\alpha, 0)}$\n",
        "\n",
        "$\\mathcal{L_\\mathrm{Full}} = \\mathcal{L_\\mathrm{1}} + \\mathcal{L_\\mathrm{2}}$"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rnrx5vPftuIj"
      },
      "source": [
        "## Similarity Scores\n",
        "The first step is to calculate the matrix of similarity scores using cosine similarity so that you can look up $\\mathrm{s}(A,P)$, $\\mathrm{s}(A,N)$ as needed for the loss formulas.\n",
        "\n",
        "### Two Vectors\n",
        "First I'll show you how to calculate the similarity score, using cosine similarity, for 2 vectors.\n",
        "\n",
        "$\\mathrm{s}(v_1,v_2) = \\mathrm{cosine \\ similarity}(v_1,v_2) = \\frac{v_1 \\cdot v_2}{||v_1||~||v_2||}$\n",
        "* Try changing the values in the second vector to see how it changes the cosine similarity.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nQ3hL7N8tuIk"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import torch"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IOnSdpA-tuIk"
      },
      "outputs": [],
      "source": [
        "def cosine_similarity(v1, v2):\n",
        "    numerator = np.dot(v1, v2)\n",
        "    denominator = np.sqrt(np.dot(v1, v1)) * np.sqrt(np.dot(v2, v2))\n",
        "    return numerator / denominator"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "r_DpXUJytuIk"
      },
      "outputs": [],
      "source": [
        "## Unnormalized Input vector\n",
        "v1 = np.array([1, 2, 3], dtype=float)\n",
        "v2 = np.array([1, 2, 3.5])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VOVX-6C6tuIl",
        "outputId": "1ac12ede-1d5f-41fc-f3bb-aff53955e1c7"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "0.9974086507360697"
            ]
          },
          "execution_count": 4,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "cosine_similarity(v1, v2)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OIIUMbeatuIl"
      },
      "source": [
        "### Two Batches of Vectors\n",
        "\n",
        "Now i'll show you how to calculate the similarity scores, using cosine similarity, for 2 batches of vectors. These are rows of individual vectors, just like in the example above, but stacked vertically into a matrix. They would look like the image below for a batch size (row count) of 4 and embedding size (column count) of 5.\n",
        "\n",
        "The data is setup so that $v_{1\\_1}$ and $v_{2\\_1}$ represent duplicate inputs, but they are not duplicates with any other rows in the batch. This means $v_{1\\_1}$ and $v_{2\\_1}$ (green and green) have more similar vectors than say $v_{1\\_1}$ and $v_{2\\_2}$ (green and magenta).\n",
        "\n",
        "I'll show you two different methods for calculating the matrix of similarities from 2 batches of vectors.\n",
        "\n",
        "<img src = 'images/v1v2_stacked.png' width=\"width\" height=\"height\" style=\"height:250px;\"/>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VrYlS9ZutuIl",
        "outputId": "ccb86e7d-2468-4be3-8be0-3b9ba59f9341"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([[ 0.9, -0.8,  0.3, -0.5],\n",
              "       [-0.4,  0.5,  0.1, -0.1],\n",
              "       [ 0.3,  0.1, -0.4, -0.8],\n",
              "       [-0.5, -0.2, -0.7,  0.5]])"
            ]
          },
          "execution_count": 5,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "sim = np.array(\n",
        "    [\n",
        "        [0.9, -0.8, 0.3, -0.5],\n",
        "        [-0.4, 0.5, 0.1, -0.1],\n",
        "        [0.3, 0.1, -0.4, -0.8],\n",
        "        [-0.5, -0.2, -0.7, 0.5],\n",
        "    ]\n",
        ")\n",
        "\n",
        "sim"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eZW_TDCrtuIm",
        "outputId": "506042d7-b9fb-4fb1-e2b8-934e314b1b09"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "4"
            ]
          },
          "execution_count": 6,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Batch size\n",
        "b = sim.shape[0]\n",
        "b"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7UAg9COOtuIm",
        "outputId": "029fb897-5aba-49a9-eae7-b957abd3a557"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([ 0.9,  0.5, -0.4,  0.5])"
            ]
          },
          "execution_count": 7,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Positives\n",
        "# All the s(A,P) values : similarities from duplicate question pairs (aka Positives)\n",
        "# These are along the diagonal\n",
        "sim_ap = np.diag(sim)\n",
        "sim_ap"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hWV0dcSVtuIm",
        "outputId": "5d7191a9-89cf-420a-e5a9-525497de0962"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([[ 0. , -0.8,  0.3, -0.5],\n",
              "       [-0.4,  0. ,  0.1, -0.1],\n",
              "       [ 0.3,  0.1,  0. , -0.8],\n",
              "       [-0.5, -0.2, -0.7,  0. ]])"
            ]
          },
          "execution_count": 8,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Negatives\n",
        "# all the s(A,N) values : similarities the non duplicate question pairs (aka Negatives)\n",
        "# These are in the off diagonals\n",
        "sim_an = sim - np.diag(sim_ap)\n",
        "sim_an"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RzyUPKmdtuIm",
        "outputId": "0da13b7c-aa14-46fc-b8d8-288cd41712f3"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([[-0.33333333],\n",
              "       [-0.13333333],\n",
              "       [-0.13333333],\n",
              "       [-0.46666667]])"
            ]
          },
          "execution_count": 9,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Mean negative\n",
        "# Average of the s(A,N) values for each row\n",
        "mean_neg = np.sum(sim_an, axis=1, keepdims=True)/ (b-1)\n",
        "mean_neg"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "L8c27Z-ItuIm",
        "outputId": "8ae3208d-c072-4d9d-96e5-f90246a65d50"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([[ 0.3],\n",
              "       [ 0.1],\n",
              "       [-0.8],\n",
              "       [-0.2]])"
            ]
          },
          "execution_count": 10,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Closest negative\n",
        "# Max s(A,N) that is <= s(A,P) for each row\n",
        "mask_1 = np.identity(b) == 1            # mask to exclude the diagonal\n",
        "mask_2 = sim_an > sim_ap.reshape(b, 1)  # mask to exclude sim_an > sim_ap\n",
        "mask = mask_1 | mask_2\n",
        "sim_an_masked = np.copy(sim_an)         # create a copy to preserve sim_an\n",
        "sim_an_masked[mask] = -2\n",
        "closest_neg = np.max(sim_an_masked, axis=1, keepdims=True)\n",
        "closest_neg"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "L-KbUKyDtuIn",
        "outputId": "150be9f6-5409-46d9-cedd-e712308bf825"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "-- Inputs --\n",
            "sim :\n",
            "[[ 0.9 -0.8  0.3 -0.5]\n",
            " [-0.4  0.5  0.1 -0.1]\n",
            " [ 0.3  0.1 -0.4 -0.8]\n",
            " [-0.5 -0.2 -0.7  0.5]]\n",
            "shape : (4, 4) \n",
            "\n",
            "sim_ap :\n",
            "[[ 0.9  0.   0.   0. ]\n",
            " [ 0.   0.5  0.   0. ]\n",
            " [ 0.   0.  -0.4  0. ]\n",
            " [ 0.   0.   0.   0.5]] \n",
            "\n",
            "sim_an :\n",
            "[[ 0.  -0.8  0.3 -0.5]\n",
            " [-0.4  0.   0.1 -0.1]\n",
            " [ 0.3  0.1  0.  -0.8]\n",
            " [-0.5 -0.2 -0.7  0. ]] \n",
            "\n",
            "-- Outputs --\n",
            "mean_neg :\n",
            "[[-0.33333333]\n",
            " [-0.13333333]\n",
            " [-0.13333333]\n",
            " [-0.46666667]] \n",
            "\n",
            "closest_neg :\n",
            "[[ 0.3]\n",
            " [ 0.1]\n",
            " [-0.8]\n",
            " [-0.2]] \n",
            "\n"
          ]
        }
      ],
      "source": [
        "## Print all\n",
        "print(\"-- Inputs --\")\n",
        "print(\"sim :\")\n",
        "print(sim)\n",
        "print(\"shape :\", sim.shape, \"\\n\")\n",
        "\n",
        "\n",
        "sim_ap = np.diag(sim)\n",
        "print(\"sim_ap :\")\n",
        "print(np.diag(sim_ap), \"\\n\")\n",
        "\n",
        "\n",
        "print(\"sim_an :\")\n",
        "print(sim_an, \"\\n\")\n",
        "\n",
        "\n",
        "print(\"-- Outputs --\")\n",
        "print(\"mean_neg :\")\n",
        "print(mean_neg, \"\\n\")\n",
        "\n",
        "print(\"closest_neg :\")\n",
        "print(closest_neg, \"\\n\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Sr47xXaKtuIn"
      },
      "source": [
        "## Torch implementation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "n8IWFE4-tuIn",
        "outputId": "a6dc1eac-a92c-43db-bd54-f227337a3b2a"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "tensor([[ 0.9000, -0.8000,  0.3000, -0.5000],\n",
              "        [-0.4000,  0.5000,  0.1000, -0.1000],\n",
              "        [ 0.3000,  0.1000, -0.4000, -0.8000],\n",
              "        [-0.5000, -0.2000, -0.7000,  0.5000]])"
            ]
          },
          "execution_count": 12,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "sim = torch.tensor(\n",
        "    [\n",
        "        [0.9, -0.8, 0.3, -0.5],\n",
        "        [-0.4, 0.5, 0.1, -0.1],\n",
        "        [0.3, 0.1, -0.4, -0.8],\n",
        "        [-0.5, -0.2, -0.7, 0.5],\n",
        "    ]\n",
        ")\n",
        "\n",
        "sim"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Kb9ryJCOtuIn",
        "outputId": "46858e8c-eeb7-4476-bfde-2aa511c6e2e9"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "tensor([ 0.9000,  0.5000, -0.4000,  0.5000])"
            ]
          },
          "execution_count": 13,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "sim_ap = torch.diag(sim, diagonal= 0)\n",
        "sim_ap"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "047omRObtuIo",
        "outputId": "a37b3fd2-83ea-4910-961a-a252490d5ced"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([[ 0.9,  0. ,  0. ,  0. ],\n",
              "       [ 0. ,  0.5,  0. ,  0. ],\n",
              "       [ 0. ,  0. , -0.4,  0. ],\n",
              "       [ 0. ,  0. ,  0. ,  0.5]], dtype=float32)"
            ]
          },
          "execution_count": 14,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "np.diag(sim_ap)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Uc6gcLW6tuIo",
        "outputId": "d7c19ecd-b4f0-4b19-df53-24278aeb7239"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "tensor([[ 0.0000, -0.8000,  0.3000, -0.5000],\n",
              "        [-0.4000,  0.0000,  0.1000, -0.1000],\n",
              "        [ 0.3000,  0.1000,  0.0000, -0.8000],\n",
              "        [-0.5000, -0.2000, -0.7000,  0.0000]])"
            ]
          },
          "execution_count": 15,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "sim_an = sim - torch.diag(sim_ap)\n",
        "sim_an"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LM9s7_HVtuIo",
        "outputId": "dbccd508-2dbd-4c57-977e-bf8e056aa794"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "tensor([[-0.3333],\n",
              "        [-0.1333],\n",
              "        [-0.1333],\n",
              "        [-0.4667]])"
            ]
          },
          "execution_count": 16,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "## mean_neg\n",
        "## devide by  (b - 1) is row sum except diagonal element\n",
        "torch.sum(sim_an, axis = 1, keepdims =True)/ (b - 1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EDKKm79utuIp",
        "outputId": "c08a3222-7440-40ce-cc0d-4a574899eb95"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "tensor([[ 0.3000],\n",
              "        [ 0.1000],\n",
              "        [-0.7000],\n",
              "        [-0.1000]])"
            ]
          },
          "execution_count": 17,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Closest negative\n",
        "# Max s(A,N) that is <= s(A,P) for each row\n",
        "mask_1 = torch.eye(b) == 1            # mask to exclude the diagonal\n",
        "mask_2 = sim_an > sim_ap.view(b, 1)  # mask to exclude sim_an > sim_ap\n",
        "mask = mask_1 | mask_2\n",
        "sim_an_masked = torch.t_copy(sim_an)       # create a copy to preserve sim_an\n",
        "sim_an_masked[mask] = -2\n",
        "closest_neg, _ = torch.max(sim_an_masked, axis=1, keepdims=True)\n",
        "closest_neg"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "lighting",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.18"
    },
    "colab": {
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}